{
 "metadata": {
  "name": "",
  "signature": "sha256:71a588db7113a23cb51af709774117bc873064d6b5e65cdf2fafa4ff01860990"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This is the notebook for Comp598 project 2.\n",
      "First we read the input for the training set. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import csv\n",
      "traininput=csv.reader(open('train_input.csv'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Skip the first line which contains the headers. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "line1=traininput.next()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Store the rows in a list. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "traininputlist=list()\n",
      "for line in traininput:\n",
      "    traininputlist.append(line)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(traininputlist)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 19,
       "text": [
        "96213"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "traininputlist[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 22,
       "text": [
        "['0',\n",
        " 'Turing machines and G\\\\\"odel numbers are important pillars of the theory of computation. Thus, any computational architecture needs to show how it could relate to Turing machines and how stable implementations of Turing computation are possible. In this chapter, we implement universal Turing computation in a neural field environment. To this end, we employ the canonical symbologram representation of a Turing machine obtained from a G\\\\\"odel encoding of its symbolic repertoire and generalized shifts. The resulting nonlinear dynamical automaton (NDA) is a piecewise affine-linear map acting on the unit square that is partitioned into rectangular domains. Instead of looking at point dynamics in phase space, we then consider functional dynamics of probability distributions functions (p.d.f.s) over phase space. This is generally described by a Frobenius-Perron integral transformation that can be regarded as a neural field equation over the unit square as feature space of a dynamic field theory (DFT). Solving the Frobenius-Perron equation yields that uniform p.d.f.s with rectangular support are mapped onto uniform p.d.f.s with rectangular support, again. We call the resulting representation \\\\emph{dynamic field automaton}.']"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we begin the cleaning step. First we experiment on a copy of the first entry. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "copy=traininputlist[0][1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "type(copy)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 25,
       "text": [
        "str"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nltk import word_tokenize\n",
      "from __future__ import division"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tokens=word_tokenize(copy)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tokens"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 30,
       "text": [
        "['Turing',\n",
        " 'machines',\n",
        " 'and',\n",
        " 'G\\\\',\n",
        " \"''\",\n",
        " 'odel',\n",
        " 'numbers',\n",
        " 'are',\n",
        " 'important',\n",
        " 'pillars',\n",
        " 'of',\n",
        " 'the',\n",
        " 'theory',\n",
        " 'of',\n",
        " 'computation',\n",
        " '.',\n",
        " 'Thus',\n",
        " ',',\n",
        " 'any',\n",
        " 'computational',\n",
        " 'architecture',\n",
        " 'needs',\n",
        " 'to',\n",
        " 'show',\n",
        " 'how',\n",
        " 'it',\n",
        " 'could',\n",
        " 'relate',\n",
        " 'to',\n",
        " 'Turing',\n",
        " 'machines',\n",
        " 'and',\n",
        " 'how',\n",
        " 'stable',\n",
        " 'implementations',\n",
        " 'of',\n",
        " 'Turing',\n",
        " 'computation',\n",
        " 'are',\n",
        " 'possible',\n",
        " '.',\n",
        " 'In',\n",
        " 'this',\n",
        " 'chapter',\n",
        " ',',\n",
        " 'we',\n",
        " 'implement',\n",
        " 'universal',\n",
        " 'Turing',\n",
        " 'computation',\n",
        " 'in',\n",
        " 'a',\n",
        " 'neural',\n",
        " 'field',\n",
        " 'environment',\n",
        " '.',\n",
        " 'To',\n",
        " 'this',\n",
        " 'end',\n",
        " ',',\n",
        " 'we',\n",
        " 'employ',\n",
        " 'the',\n",
        " 'canonical',\n",
        " 'symbologram',\n",
        " 'representation',\n",
        " 'of',\n",
        " 'a',\n",
        " 'Turing',\n",
        " 'machine',\n",
        " 'obtained',\n",
        " 'from',\n",
        " 'a',\n",
        " 'G\\\\',\n",
        " \"''\",\n",
        " 'odel',\n",
        " 'encoding',\n",
        " 'of',\n",
        " 'its',\n",
        " 'symbolic',\n",
        " 'repertoire',\n",
        " 'and',\n",
        " 'generalized',\n",
        " 'shifts',\n",
        " '.',\n",
        " 'The',\n",
        " 'resulting',\n",
        " 'nonlinear',\n",
        " 'dynamical',\n",
        " 'automaton',\n",
        " '(',\n",
        " 'NDA',\n",
        " ')',\n",
        " 'is',\n",
        " 'a',\n",
        " 'piecewise',\n",
        " 'affine-linear',\n",
        " 'map',\n",
        " 'acting',\n",
        " 'on',\n",
        " 'the',\n",
        " 'unit',\n",
        " 'square',\n",
        " 'that',\n",
        " 'is',\n",
        " 'partitioned',\n",
        " 'into',\n",
        " 'rectangular',\n",
        " 'domains',\n",
        " '.',\n",
        " 'Instead',\n",
        " 'of',\n",
        " 'looking',\n",
        " 'at',\n",
        " 'point',\n",
        " 'dynamics',\n",
        " 'in',\n",
        " 'phase',\n",
        " 'space',\n",
        " ',',\n",
        " 'we',\n",
        " 'then',\n",
        " 'consider',\n",
        " 'functional',\n",
        " 'dynamics',\n",
        " 'of',\n",
        " 'probability',\n",
        " 'distributions',\n",
        " 'functions',\n",
        " '(',\n",
        " 'p.d.f.s',\n",
        " ')',\n",
        " 'over',\n",
        " 'phase',\n",
        " 'space',\n",
        " '.',\n",
        " 'This',\n",
        " 'is',\n",
        " 'generally',\n",
        " 'described',\n",
        " 'by',\n",
        " 'a',\n",
        " 'Frobenius-Perron',\n",
        " 'integral',\n",
        " 'transformation',\n",
        " 'that',\n",
        " 'can',\n",
        " 'be',\n",
        " 'regarded',\n",
        " 'as',\n",
        " 'a',\n",
        " 'neural',\n",
        " 'field',\n",
        " 'equation',\n",
        " 'over',\n",
        " 'the',\n",
        " 'unit',\n",
        " 'square',\n",
        " 'as',\n",
        " 'feature',\n",
        " 'space',\n",
        " 'of',\n",
        " 'a',\n",
        " 'dynamic',\n",
        " 'field',\n",
        " 'theory',\n",
        " '(',\n",
        " 'DFT',\n",
        " ')',\n",
        " '.',\n",
        " 'Solving',\n",
        " 'the',\n",
        " 'Frobenius-Perron',\n",
        " 'equation',\n",
        " 'yields',\n",
        " 'that',\n",
        " 'uniform',\n",
        " 'p.d.f.s',\n",
        " 'with',\n",
        " 'rectangular',\n",
        " 'support',\n",
        " 'are',\n",
        " 'mapped',\n",
        " 'onto',\n",
        " 'uniform',\n",
        " 'p.d.f.s',\n",
        " 'with',\n",
        " 'rectangular',\n",
        " 'support',\n",
        " ',',\n",
        " 'again',\n",
        " '.',\n",
        " 'We',\n",
        " 'call',\n",
        " 'the',\n",
        " 'resulting',\n",
        " 'representation',\n",
        " '\\\\emph',\n",
        " '{',\n",
        " 'dynamic',\n",
        " 'field',\n",
        " 'automaton',\n",
        " '}',\n",
        " '.']"
       ]
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(tokens)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 31,
       "text": [
        "204"
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We have created a list of length 204, each containing a token. Now we make all the words case-neutral. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "temp=[word.lower() for word in tokens]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(temp)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 33,
       "text": [
        "204"
       ]
      }
     ],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import re\n",
      "#Keep the word if it has more alphabetic characters than others\n",
      "keeplist=list()\n",
      "for word in temp:\n",
      "    sumalpha=sum(1 for w in word if re.search('[a-z]',w))\n",
      "    sumothers=len(word)-sumalpha\n",
      "    keeplist.append(sumalpha>sumothers)\n",
      "trimmedlist=list()\n",
      "for i in range(0,len(temp)):\n",
      "    if(keeplist[i]==True):\n",
      "        trimmedlist.append(temp[i])\n",
      "    \n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 91
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We have created a list of words from a string such that each word contains more alphabetic charcaters than non-alphabetic characters. Now we proceed to remove non-essentail parts of speech: determiner, preposition, prnoun and conjunction. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import nltk\n",
      "taggedlist=nltk.pos_tag(trimmedlist)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 98
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Obtain the tagset by nltk.help.upenn.tagset()"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "postoexclude=[\"CC\",\"DT\",\"IN\",\"MD\",\"PDT\",\"PRP\",\"PRP$\",\"RP\",\"TO\",\"WDT\",\"WP\",\"WP$\",\"WRB\"]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 97
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Get all the words that don't have the parts-of-speech in the to-exclude list"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "trimmedlist2=[word[0] for word in taggedlist if word[1] not in set(postoexclude)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 114
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Filter a second time, this time excluding words from a custom list."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "txt=open('20mostpopularwords','r')\n",
      "forbbidenwordslist=word_tokenize(txt.read())\n",
      "trimmedlist3=[word for word in trimmedlist2 if word not in set(forbbidenwordslist)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 124
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(trimmedlist3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 125,
       "text": [
        "110"
       ]
      }
     ],
     "prompt_number": 125
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "trimmedlist3"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 126,
       "text": [
        "['turing',\n",
        " 'machines',\n",
        " 'odel',\n",
        " 'numbers',\n",
        " 'pillars',\n",
        " 'theory',\n",
        " 'computation',\n",
        " 'thus',\n",
        " 'computational',\n",
        " 'architecture',\n",
        " 'needs',\n",
        " 'show',\n",
        " 'relate',\n",
        " 'turing',\n",
        " 'machines',\n",
        " 'stable',\n",
        " 'implementations',\n",
        " 'turing',\n",
        " 'computation',\n",
        " 'possible',\n",
        " 'chapter',\n",
        " 'implement',\n",
        " 'universal',\n",
        " 'turing',\n",
        " 'computation',\n",
        " 'neural',\n",
        " 'field',\n",
        " 'environment',\n",
        " 'end',\n",
        " 'employ',\n",
        " 'canonical',\n",
        " 'symbologram',\n",
        " 'representation',\n",
        " 'turing',\n",
        " 'machine',\n",
        " 'obtained',\n",
        " 'odel',\n",
        " 'encoding',\n",
        " 'symbolic',\n",
        " 'repertoire',\n",
        " 'generalized',\n",
        " 'shifts',\n",
        " 'resulting',\n",
        " 'nonlinear',\n",
        " 'dynamical',\n",
        " 'automaton',\n",
        " 'nda',\n",
        " 'piecewise',\n",
        " 'affine-linear',\n",
        " 'map',\n",
        " 'acting',\n",
        " 'unit',\n",
        " 'square',\n",
        " 'partitioned',\n",
        " 'rectangular',\n",
        " 'domains',\n",
        " 'instead',\n",
        " 'looking',\n",
        " 'point',\n",
        " 'dynamics',\n",
        " 'phase',\n",
        " 'space',\n",
        " 'then',\n",
        " 'consider',\n",
        " 'functional',\n",
        " 'dynamics',\n",
        " 'probability',\n",
        " 'distributions',\n",
        " 'functions',\n",
        " 'p.d.f.s',\n",
        " 'phase',\n",
        " 'space',\n",
        " 'generally',\n",
        " 'described',\n",
        " 'frobenius-perron',\n",
        " 'integral',\n",
        " 'transformation',\n",
        " 'regarded',\n",
        " 'neural',\n",
        " 'field',\n",
        " 'equation',\n",
        " 'unit',\n",
        " 'square',\n",
        " 'feature',\n",
        " 'space',\n",
        " 'dynamic',\n",
        " 'field',\n",
        " 'theory',\n",
        " 'dft',\n",
        " 'solving',\n",
        " 'frobenius-perron',\n",
        " 'equation',\n",
        " 'yields',\n",
        " 'uniform',\n",
        " 'p.d.f.s',\n",
        " 'rectangular',\n",
        " 'support',\n",
        " 'mapped',\n",
        " 'uniform',\n",
        " 'p.d.f.s',\n",
        " 'rectangular',\n",
        " 'support',\n",
        " 'again',\n",
        " 'call',\n",
        " 'resulting',\n",
        " 'representation',\n",
        " '\\\\emph',\n",
        " 'dynamic',\n",
        " 'field',\n",
        " 'automaton']"
       ]
      }
     ],
     "prompt_number": 126
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we can proceed with stemming. We are using the Porter stemmer available in the NLTK package."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "porter=nltk.PorterStemmer()\n",
      "stemmedlist=[porter.stem(word) for word in trimmedlist3]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 127
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "stemmedlist"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 128,
       "text": [
        "[u'ture',\n",
        " u'machin',\n",
        " u'odel',\n",
        " u'number',\n",
        " u'pillar',\n",
        " u'theori',\n",
        " u'comput',\n",
        " u'thu',\n",
        " u'comput',\n",
        " u'architectur',\n",
        " u'need',\n",
        " u'show',\n",
        " u'relat',\n",
        " u'ture',\n",
        " u'machin',\n",
        " u'stabl',\n",
        " u'implement',\n",
        " u'ture',\n",
        " u'comput',\n",
        " u'possibl',\n",
        " u'chapter',\n",
        " u'implement',\n",
        " u'univers',\n",
        " u'ture',\n",
        " u'comput',\n",
        " u'neural',\n",
        " u'field',\n",
        " u'environ',\n",
        " u'end',\n",
        " u'employ',\n",
        " u'canon',\n",
        " u'symbologram',\n",
        " u'represent',\n",
        " u'ture',\n",
        " u'machin',\n",
        " u'obtain',\n",
        " u'odel',\n",
        " u'encod',\n",
        " u'symbol',\n",
        " u'repertoir',\n",
        " u'gener',\n",
        " u'shift',\n",
        " u'result',\n",
        " u'nonlinear',\n",
        " u'dynam',\n",
        " u'automaton',\n",
        " u'nda',\n",
        " u'piecewis',\n",
        " u'affine-linear',\n",
        " u'map',\n",
        " u'act',\n",
        " u'unit',\n",
        " u'squar',\n",
        " u'partit',\n",
        " u'rectangular',\n",
        " u'domain',\n",
        " u'instead',\n",
        " u'look',\n",
        " u'point',\n",
        " u'dynam',\n",
        " u'phase',\n",
        " u'space',\n",
        " u'then',\n",
        " u'consid',\n",
        " u'function',\n",
        " u'dynam',\n",
        " u'probabl',\n",
        " u'distribut',\n",
        " u'function',\n",
        " u'p.d.f.',\n",
        " u'phase',\n",
        " u'space',\n",
        " u'gener',\n",
        " u'describ',\n",
        " u'frobenius-perron',\n",
        " u'integr',\n",
        " u'transform',\n",
        " u'regard',\n",
        " u'neural',\n",
        " u'field',\n",
        " u'equat',\n",
        " u'unit',\n",
        " u'squar',\n",
        " u'featur',\n",
        " u'space',\n",
        " u'dynam',\n",
        " u'field',\n",
        " u'theori',\n",
        " u'dft',\n",
        " u'solv',\n",
        " u'frobenius-perron',\n",
        " u'equat',\n",
        " u'yield',\n",
        " u'uniform',\n",
        " u'p.d.f.',\n",
        " u'rectangular',\n",
        " u'support',\n",
        " u'map',\n",
        " u'uniform',\n",
        " u'p.d.f.',\n",
        " u'rectangular',\n",
        " u'support',\n",
        " u'again',\n",
        " u'call',\n",
        " u'result',\n",
        " u'represent',\n",
        " u'\\\\emph',\n",
        " u'dynam',\n",
        " u'field',\n",
        " u'automaton']"
       ]
      }
     ],
     "prompt_number": 128
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Convert list into a string whose words are separated by a white space."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "str1=' '.join(stemmedlist)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 129
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "str1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 130,
       "text": [
        "u'ture machin odel number pillar theori comput thu comput architectur need show relat ture machin stabl implement ture comput possibl chapter implement univers ture comput neural field environ end employ canon symbologram represent ture machin obtain odel encod symbol repertoir gener shift result nonlinear dynam automaton nda piecewis affine-linear map act unit squar partit rectangular domain instead look point dynam phase space then consid function dynam probabl distribut function p.d.f. phase space gener describ frobenius-perron integr transform regard neural field equat unit squar featur space dynam field theori dft solv frobenius-perron equat yield uniform p.d.f. rectangular support map uniform p.d.f. rectangular support again call result represent \\\\emph dynam field automaton'"
       ]
      }
     ],
     "prompt_number": 130
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now repeat computation over the entire list of training data. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Output: list containing a cleaned abstract in each entry\n",
      "import time\n",
      "presenttime=time.clock()\n",
      "txt=open('20mostpopularwords','r')\n",
      "forbbidenwordslist=word_tokenize(txt.read())\n",
      "postoexclude=[\"CC\",\"DT\",\"IN\",\"MD\",\"PDT\",\"PRP\",\"PRP$\",\"RP\",\"TO\",\"WDT\",\"WP\",\"WP$\",\"WRB\"]\n",
      "\n",
      "cleanedtrainlist=list()\n",
      "for i in range(0,len(traininputlist)) :\n",
      "    item=traininputlist[i]\n",
      "    temp=item[1]\n",
      "    #tokenize (separate words by white space)\n",
      "    tokens=word_tokenize(temp)\n",
      "    #convert all texts to lowercase\n",
      "    temp=[word.lower() for word in tokens]\n",
      "    import re\n",
      "    #Keep the word if it has more alphabetic characters than others\n",
      "    keeplist=list()\n",
      "    for word in temp:\n",
      "        sumalpha=sum(1 for w in word if re.search('[a-z]',w))\n",
      "        sumothers=len(word)-sumalpha\n",
      "        keeplist.append(sumalpha>sumothers)\n",
      "    trimmedlist=list()\n",
      "    for i in range(0,len(temp)):\n",
      "        if(keeplist[i]==True):\n",
      "            trimmedlist.append(temp[i])\n",
      "    #Tag part-of-speeches and remove words with non-essential pos's\n",
      "    import nltk\n",
      "    taggedlist=nltk.pos_tag(trimmedlist)\n",
      "    trimmedlist2=[word[0] for word in taggedlist if word[1] not in set(postoexclude)]\n",
      "    #Remove non-essential words from a custom list \n",
      "    trimmedlist3=[word for word in trimmedlist2 if word not in set(forbbidenwordslist)]\n",
      "    #Stemming \n",
      "    porter=nltk.PorterStemmer()\n",
      "    stemmedlist=[porter.stem(word) for word in trimmedlist3]\n",
      "    #Convert list of cleaned words into a string separated by white space\n",
      "    str1=' '.join(stemmedlist)\n",
      "    cleanedtrainlist.append(str1)\n",
      "traintime=presenttime-time.clock()\n",
      "\n",
      "#Clean Test set \n",
      "import time\n",
      "presenttime=time.clock()\n",
      "testinput=csv.reader(open('test_input.csv'))\n",
      "line1=testinput.next()\n",
      "testinputlist=list()\n",
      "for line in testinput:\n",
      "    testinputlist.append(line)\n",
      "#Output: list containing a cleaned abstract in each entry\n",
      "txt=open('20mostpopularwords','r')\n",
      "forbbidenwordslist=word_tokenize(txt.read())\n",
      "postoexclude=[\"CC\",\"DT\",\"IN\",\"MD\",\"PDT\",\"PRP\",\"PRP$\",\"RP\",\"TO\",\"WDT\",\"WP\",\"WP$\",\"WRB\"]\n",
      "\n",
      "cleanedtestlist=list()\n",
      "for i in range(0,len(testinputlist)) :\n",
      "    item=testinputlist[i]\n",
      "    temp=item[1]\n",
      "    #tokenize (separate words by white space)\n",
      "    tokens=word_tokenize(temp)\n",
      "    #convert all texts to lowercase\n",
      "    temp=[word.lower() for word in tokens]\n",
      "    import re\n",
      "    #Keep the word if it has more alphabetic characters than others\n",
      "    keeplist=list()\n",
      "    for word in temp:\n",
      "        sumalpha=sum(1 for w in word if re.search('[a-z]',w))\n",
      "        sumothers=len(word)-sumalpha\n",
      "        keeplist.append(sumalpha>sumothers)\n",
      "    trimmedlist=list()\n",
      "    for i in range(0,len(temp)):\n",
      "        if(keeplist[i]==True):\n",
      "            trimmedlist.append(temp[i])\n",
      "    #Tag part-of-speeches and remove words with non-essential pos's\n",
      "    import nltk\n",
      "    taggedlist=nltk.pos_tag(trimmedlist)\n",
      "    trimmedlist2=[word[0] for word in taggedlist if word[1] not in set(postoexclude)]\n",
      "    #Remove non-essential words from a custom list \n",
      "    trimmedlist3=[word for word in trimmedlist2 if word not in set(forbbidenwordslist)]\n",
      "    #Stemming \n",
      "    porter=nltk.PorterStemmer()\n",
      "    stemmedlist=[porter.stem(word) for word in trimmedlist3]\n",
      "    #Convert list of cleaned words into a string separated by white space\n",
      "    str1=' '.join(stemmedlist)\n",
      "    cleanedtestlist.append(str1)\n",
      "testtime=time.clock()-presenttime"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 159
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Running time for cleaning the training set in seconds. I made a mistake so the time is shown in its negative value."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "traintime"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 161,
       "text": [
        "-19620.071014"
       ]
      }
     ],
     "prompt_number": 161
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(cleanedtrainlist)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 163,
       "text": [
        "128283"
       ]
      }
     ],
     "prompt_number": 163
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(traininputlist)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 164,
       "text": [
        "128283"
       ]
      }
     ],
     "prompt_number": 164
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Running for cleaning the test set in seconds."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "testtime"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 172,
       "text": [
        "5126.682101999999"
       ]
      }
     ],
     "prompt_number": 172
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Backup file just in case."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pickle\n",
      "pickle.dump(cleanedtrainlist,open('cleanedtrainlist','w'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 170
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Backup file just in case."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pickle\n",
      "pickle.dump(cleanedtestlist,open('cleanedtestlist','w'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 173
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Write the cleaned lists to file as csv."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import csv \n",
      "cleanedtrainset=open(\"cleanedtrainset.csv\",\"w\")\n",
      "writer=csv.writer(cleanedtrainset,delimiter=\",\")\n",
      "for line in cleanedtrainlist:\n",
      "    writer.writerow([line,])\n",
      "cleanedtrainset.close()\n",
      "cleanedtestset=open(\"cleanedtestset.csv\",\"w\")\n",
      "writer=csv.writer(cleanedtestset,delimiter=\",\")\n",
      "for line in cleanedtestlist:\n",
      "    writer.writerow([line,])\n",
      "cleanedtestset.close()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 189
    }
   ],
   "metadata": {}
  }
 ]
}